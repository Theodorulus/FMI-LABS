{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P56bns_L5p2k",
        "outputId": "32336cec-b947-4142-91f7-d6db2f6e252a"
      },
      "source": [
        "!unzip data_lab5.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data_lab5.zip\n",
            "  inflating: data/test_labels.npy    \n",
            "  inflating: data/test_sentences.npy  \n",
            "  inflating: data/training_labels.npy  \n",
            "  inflating: data/training_sentences.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrWpHlxCOahm"
      },
      "source": [
        "def normalize_data(train_data, test_data, type=None):\r\n",
        "  if type == 'standard':\r\n",
        "    scaler = preprocessing.StandardScaler()\r\n",
        "    scaler.fit(train_data)\r\n",
        "    scaled_train_data = scaler.transform(train_data)\r\n",
        "    scaled_test_data = scaler.transform(test_data)\r\n",
        "\r\n",
        "  if type == 'l1':\r\n",
        "    scaler = preprocessing.Normalizer(norm='l1')\r\n",
        "    scaler.fit(train_data)\r\n",
        "    scaled_train_data = scaler.transform(train_data)\r\n",
        "    scaled_test_data = scaler.transform(test_data)\r\n",
        "\r\n",
        "  if type == 'l2':\r\n",
        "    scaler = preprocessing.Normalizer(norm='l2')\r\n",
        "    scaler.fit(train_data)\r\n",
        "    scaled_train_data = scaler.transform(train_data)\r\n",
        "    scaled_test_data = scaler.transform(test_data)\r\n",
        "\r\n",
        "  else:\r\n",
        "    scaled_train_data = train_data\r\n",
        "    scaled_test_data = test_data\r\n",
        "\r\n",
        "  return scaled_train_data, scaled_test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bmeCmC_Oajv"
      },
      "source": [
        " class BagOfWords:\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        self.vocabular = {}\r\n",
        "        self.cuvinte = []\r\n",
        "        self.id = 0\r\n",
        "\r\n",
        "    def build_vocabulary (self, data):\r\n",
        "        for eseu in data:\r\n",
        "            for cuvant in eseu:\r\n",
        "                if cuvant not in self.vocabular.keys():\r\n",
        "                    self.vocabular[cuvant] = self.id\r\n",
        "                    self.id += 1\r\n",
        "                    self.cuvinte.append(cuvant)\r\n",
        "\r\n",
        "    def get_features (self, data):\r\n",
        "        features = np.zeros((len(data), self.id))\r\n",
        "        # id_sample = -1\r\n",
        "        for id_sample, sample in enumerate(data):\r\n",
        "            # id_sample += 1\r\n",
        "            for word in sample:\r\n",
        "                if word in self.vocabular.keys():\r\n",
        "                    features[id_sample][self.vocabular[word]] += 1\r\n",
        "        return features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD4kaDswOal1"
      },
      "source": [
        "train_data = np.load('data/training_sentences.npy', allow_pickle=True)\r\n",
        "train_labels = np.load('data/training_labels.npy', allow_pickle=True)\r\n",
        "\r\n",
        "test_data = np.load('data/test_sentences.npy', allow_pickle=True)\r\n",
        "test_labels = np.load('data/test_labels.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_13-EcPvOaoA",
        "outputId": "c02d8641-56a6-408e-fdad-b80e637611ae"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsWNRGlzOaqR"
      },
      "source": [
        "bow = BagOfWords()\r\n",
        "bow.build_vocabulary(train_data)\r\n",
        "train = bow.get_features(train_data)\r\n",
        "test = bow.get_features(test_data)\r\n",
        "normalized_train, normalized_test = normalize_data(train, test, 'l2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW1erzKQOasf",
        "outputId": "94d013ef-7bd4-4130-9ebd-354003cae260"
      },
      "source": [
        "print(normalized_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.35355339 0.35355339 0.35355339 ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.19611614 0.19611614 0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.33333333]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrrYHgZjOauz",
        "outputId": "d801936a-6d4d-4649-b0d6-9a2657a65c82"
      },
      "source": [
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import accuracy_score, f1_score\r\n",
        "\r\n",
        "\r\n",
        "# instantiate SVM\r\n",
        "model = SVC(C=1, kernel='linear')\r\n",
        "# fit SVM\r\n",
        "model.fit(normalized_train, train_labels)\r\n",
        "# get predictions SVM\r\n",
        "predict = model.predict(normalized_test)\r\n",
        "# calculate accuracy/f1\r\n",
        "print(accuracy_score(test_labels, predict))\r\n",
        "print(f1_score(test_labels, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9842391304347826\n",
            "0.9409368635437881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "926jHaioOaw8",
        "outputId": "89235b93-a355-48b5-f848-afd5678c6bad"
      },
      "source": [
        "model.coef_[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0120314 , -0.11716947, -0.63366342, ...,  0.        ,\n",
              "        0.        ,  0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mJUknA9Oazd",
        "outputId": "e13ca700-d2f3-419d-d52a-c049ccafbeaa"
      },
      "source": [
        "idxes = np.argsort(model.coef_[0])\r\n",
        "\r\n",
        "print(idxes.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9522,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e5GyXofOa1b",
        "outputId": "1b85b22a-0ff4-4203-a068-8f6d18b26118"
      },
      "source": [
        "print(np.min(model.coef_[0]))\r\n",
        "print(model.coef_[0][idxes[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.5205706281988167\n",
            "-1.5205706281988167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azbPZsa6Oa3r",
        "outputId": "6cb9e3f6-7b6d-4a46-b9bf-9a467d74ad73"
      },
      "source": [
        "print([bow.cuvinte[i] for i in idxes[:10]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['&lt#&gt', 'me', 'i', 'Going', 'him', 'Ok', 'I', 'Ill', 'my', 'Im']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiOecSMROa5u",
        "outputId": "4bb165e4-56d3-4bdf-a003-8626aaa1a8a0"
      },
      "source": [
        "print([bow.cuvinte[i] for i in idxes[-10:]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Text', 'To', 'mobile', 'CALL', 'FREE', 'txt', '&', 'Call', 'Txt', 'STOP']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biKi4xKpOa8B"
      },
      "source": [
        " class BagOfWords:\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        self.vocabular = {}\r\n",
        "        self.cuvinte = []\r\n",
        "        self.id = 0\r\n",
        "\r\n",
        "    def build_vocabulary(self, data, vocab_size=5000):\r\n",
        "        for eseu in data:\r\n",
        "            for cuvant in eseu:\r\n",
        "                if cuvant not in self.vocabular.keys():\r\n",
        "                    self.vocabular[cuvant] = self.id\r\n",
        "                    self.id += 1\r\n",
        "                    self.cuvinte.append(cuvant)\r\n",
        "\r\n",
        "    def get_features (self, data):\r\n",
        "        features = np.zeros((len(data), self.id))\r\n",
        "        # id_sample = -1\r\n",
        "        for id_sample, sample in enumerate(data):\r\n",
        "            # id_sample += 1\r\n",
        "            for word in sample:\r\n",
        "                if word in self.vocabular.keys():\r\n",
        "                    features[id_sample][self.vocabular[word]] += 1\r\n",
        "        return features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8b_ND02q2q7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr29q1Cyq2tD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk1eRNQlOa-f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxUR5aUpObAh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK7c4BprObCw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co_YplUtH8U8"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zo4DKd3HwjJ",
        "outputId": "107883db-89bf-49df-a384-00e0dd2cd9cb"
      },
      "source": [
        "train_data = np.load('data/training_sentences.npy', allow_pickle=True)\r\n",
        "train_labels = np.load('data/training_labels.npy', allow_pickle=True)\r\n",
        "\r\n",
        "test_data = np.load('data/test_sentences.npy', allow_pickle=True)\r\n",
        "test_labels = np.load('data/test_labels.npy', allow_pickle=True)\r\n",
        "\r\n",
        "X_train, y_train = np.load('data/training_sentences.npy', allow_pickle=True), np.load('data/training_labels.npy', allow_pickle=True)\r\n",
        "X_test, y_test = np.load('data/test_sentences.npy', allow_pickle=True), np.load('data/test_labels.npy', allow_pickle=True)\r\n",
        "\r\n",
        "\r\n",
        "print(X_train.shape)\r\n",
        "print(X_test.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3734,)\n",
            "(1840,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4KtAnlWH7ZP"
      },
      "source": [
        "import sklearn.preprocessing as preprocessing\r\n",
        "\r\n",
        "#2\r\n",
        "def normalize_data(train_data, test_data, type=None):\r\n",
        "    if type == 'standard':\r\n",
        "        scaler = preprocessing.StandardScaler()\r\n",
        "    elif type == 'l1':\r\n",
        "        scaler = preprocessing.Normalizer(norm='l1')\r\n",
        "    elif type == 'l2':\r\n",
        "        scaler = preprocessing.Normalizer(norm='l2')\r\n",
        "\r\n",
        "    if scaler is not None:\r\n",
        "        scaler.fit(train_data)\r\n",
        "        sc_train = scaler.transform(train_data)\r\n",
        "        sc_test = scaler.transform(test_data)\r\n",
        "        return sc_train, sc_test\r\n",
        "    return train_data, test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXIM0k6FJ8wC",
        "outputId": "eb11b8af-5216-4f45-94dc-2831be0a029f"
      },
      "source": [
        "def normalize_data(train_data, test_data, type = None):\r\n",
        "    n_train_data = train_data\r\n",
        "    n_test_data = test_data\r\n",
        "    if type == 'standard':\r\n",
        "        scaler = preprocessing.StandardScaler()\r\n",
        "        scaler.fit(train_data)\r\n",
        "        n_train_data = scaler.transform(train_data)\r\n",
        "        n_test_data = scaler.transform(test_data)\r\n",
        "    elif type == 'l1':\r\n",
        "        x_norm = np.sum(abs(train_data), axis = 1)\r\n",
        "        n_train_data = train_data/x_norm\r\n",
        "        n_test_data = test_data/x_norm\r\n",
        "    elif type == 'l2':\r\n",
        "        x_norm = np.sqrt(np.sum((train_data ** 2), axis = 1))\r\n",
        "        # print(np.sqrt(np.sum((train_data ** 2), axis = 1)).shape)\r\n",
        "        # print(train_data.shape)\r\n",
        "\r\n",
        "        # print(np.sqrt(np.sum((test_data ** 2), axis = 1)).shape)\r\n",
        "        # print(test_data.shape)\r\n",
        "        n_train_data = train_data / np.sqrt(np.sum((train_data ** 2), axis = 1).reshape(3734, 1))\r\n",
        "        n_test_data = test_data / np.sqrt(np.sum((test_data ** 2), axis = 1).reshape(1840, 1))\r\n",
        "    return n_train_data, n_test_data\r\n",
        "\r\n",
        "normalize_data(X_train, X_test, type='l2')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3734, 9522)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3HKbtl1H69E"
      },
      "source": [
        "class BagOfWords():\r\n",
        "    def __init__(self):\r\n",
        "        self.words = []\r\n",
        "        self.word_to_id = {}\r\n",
        "        \r\n",
        "    def build_vocabulary(self, data):\r\n",
        "        for sentence in data:\r\n",
        "            for word in sentence:\r\n",
        "                if word not in self.word_to_id:\r\n",
        "                    self.word_to_id[word] = len(self.words)\r\n",
        "                    self.words.append(word)\r\n",
        "                    \r\n",
        "    def get_features(self, data):\r\n",
        "        # features = np.array([[0 for _ in range(len(self.words))] for _ in range(len(data))])\r\n",
        "        features = np.zeros((len(data), len(self.words)))\r\n",
        "        for sentence_id, sentence in enumerate(data):\r\n",
        "            for word in sentence:\r\n",
        "                if word in self.word_to_id:\r\n",
        "                    features[sentence_id][self.word_to_id[word]] += 1\r\n",
        "        return features\r\n",
        "        \r\n",
        "bow = BagOfWords()\r\n",
        "bow.build_vocabulary(X_train)\r\n",
        "X_train = bow.get_features(X_train)\r\n",
        "X_test  = bow.get_features(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsC48oOYIvTJ",
        "outputId": "c6ec88d6-0c0d-4fb7-d328-b3fbb6903b4b"
      },
      "source": [
        "train_normalised, test_normalised = normalize_data(X_train, X_test, type='l2')\r\n",
        "\r\n",
        "print(train_normalised[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.08276059 0.08276059 0.99312707 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKwBARGWJd8M",
        "outputId": "16cc30fa-33bb-44b5-c4d7-66edad40df0a"
      },
      "source": [
        "import sklearn.svm as svm\r\n",
        "from sklearn.metrics import accuracy_score, f1_score\r\n",
        "\r\n",
        "vect_class = svm.SVC(C=1, kernel='linear')\r\n",
        "vect_class.fit(X_train, train_labels)\r\n",
        "\r\n",
        "test_predict = vect_class.predict(X_test)\r\n",
        "print('Accuracy: ', accuracy_score(test_labels, test_predict))\r\n",
        "\r\n",
        "print('F1 score: ', f1_score(test_labels, test_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9847826086956522\n",
            "F1 score:  0.9423868312757202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgFv4AR5MtYH",
        "outputId": "cc962ebf-c1c7-4f96-e67c-8813f18df822"
      },
      "source": [
        "vect_class.coef_.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 9522)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWLyIIY0M8SB",
        "outputId": "6b939caa-1aaa-4e4e-bb86-5e2c805160d9"
      },
      "source": [
        "print(np.min(vect_class.coef_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.3916800190214731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6dtltSWLcTE"
      },
      "source": [
        "sc = np.argsort(vect_class.coef_)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgs5XPFMMz1u",
        "outputId": "b144b24a-83c4-4a4c-8c5e-1de2e50dad78"
      },
      "source": [
        "print(sc.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9522,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAREs3dBMbPE",
        "outputId": "0feb3e81-7456-44ac-c765-cbb2224a582c"
      },
      "source": [
        "print(sc[0])\r\n",
        "print(vect_class.coef_[0, sc[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "207\n",
            "-0.3916800190214731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w62f9YWMmMD",
        "outputId": "13729398-e303-4e0d-aeba-5c95590d2e24"
      },
      "source": [
        "top_negative_words = [bow.words[i] for i in sc[:10]]\r\n",
        "print(top_negative_words)\r\n",
        "\r\n",
        "# NOT SPAM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['&lt#&gt', 'him', 'Oh', 'Waiting', 'Alright', 'me', 'Lmaonice', 'always', 'It', 'goal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuoLvx9rNRqJ",
        "outputId": "c8d7f7fe-9f21-4a98-bd7c-36519a056703"
      },
      "source": [
        "top_positive_words = [bow.words[i] for i in sc[-10:]]\r\n",
        "print(top_positive_words)\r\n",
        "\r\n",
        "# SPAM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['For', 'Txt', 'widelivecomindex', 'httptms', 'FREE>RingtoneReply', '85233', 'won', 'REAL', 'ringtoneking', '84484']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcC4x2r_NkVl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}